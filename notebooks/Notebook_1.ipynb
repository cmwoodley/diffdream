{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from diffusers import DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,\"../scripts\")\n",
    "from get_voxels import get_mol_voxels\n",
    "from networks import Encoder, UNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "encoder = Encoder()\n",
    "encoder.to(device)\n",
    "\n",
    "encoder.load_state_dict(torch.load(\"../models/state_dict_encoder.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "with open(\"../datasets/raw/zinc15_druglike_clean_canonical_max60.smi\") as f:\n",
    "    i=0\n",
    "    for i, line in enumerate(f):\n",
    "        smiles.append(line)\n",
    "        if i > 250000:\n",
    "            break\n",
    "\n",
    "smiles = smiles[216000:]\n",
    "\n",
    "# inputs = []\n",
    "# targets = []\n",
    "\n",
    "# for i in range(len(smiles)):\n",
    "#     try:\n",
    "#         inp, targ = get_mol_voxels(smiles[i])\n",
    "#         inputs.append(inp)\n",
    "#         targets.append(targ)\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "# inputs = torch.stack(inputs)\n",
    "# targets = torch.stack(targets)\n",
    "\n",
    "# with open(\"input.sav\",\"wb\") as f:\n",
    "#     torch.save(inputs, f)\n",
    "\n",
    "# with open(\"target.sav\",\"wb\") as f:\n",
    "#     torch.save(targets, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up custom dataloader with vox encoding\n",
    "\n",
    "Collate_bach generates vox representations on the fly, prevent kernel crash due to being out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, smiles):\n",
    "        self.transform = get_mol_voxels\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        return smile\n",
    "\n",
    "smile_DS = CustomImageDataset(smiles)\n",
    "\n",
    "def collate_batch(smiles):\n",
    "    inputs = []\n",
    "    target = []\n",
    "    for smile in smiles:\n",
    "        try:\n",
    "            rep, pharm = get_mol_voxels(smile)\n",
    "            inputs.append(rep)\n",
    "            target.append(pharm)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return torch.stack(inputs), torch.stack(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader (you can mess with batch size)\n",
    "train_dataloader = DataLoader(smile_DS, batch_size=128, collate_fn=collate_batch)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epochs = 1\n",
    "\n",
    "# Our loss finction\n",
    "criterion = nn.MSELoss()\n",
    "# The optimizer\n",
    "optimizer = torch.optim.Adam(encoder.parameters())\n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses_enc = []\n",
    "\n",
    "# Initialize the DDPM scheduler\n",
    "ddpm = DDPMScheduler(num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i, (x, targets) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        encoded_tensor = encoder(x)\n",
    "        loss = criterion(encoded_tensor, targets)\n",
    "        losses_enc.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            torch.save(encoder.state_dict(), \"../models/state_dict_encoder.pt\")\n",
    "\n",
    "    # Print our the average of the loss values for this epoch:\n",
    "    avg_loss = sum(losses_enc[-len(train_dataloader):])/len(train_dataloader)\n",
    "    print(f'Finished epoch {epoch}. Average enc loss for this epoch: {avg_loss:05f}')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfdcb42f28>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses_enc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the unet\n",
    "\n",
    "Ideally would train both at the same time, but memory becomes an issue - running on a laptop with only 4GB gpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet3D(in_channels=5, num_classes=5)\n",
    "net.to(device)\n",
    "\n",
    "net.load_state_dict(torch.load(\"../models/state_dict_net.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many runs through the data should we do?\n",
    "n_epochs = 1\n",
    "\n",
    "train_dataloader = DataLoader(smile_DS, batch_size=32, collate_fn=collate_batch)\n",
    "\n",
    "# Our loss finction\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(net.parameters(), lr=0.001) \n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses_net = []\n",
    "# Initialize the DDPM scheduler\n",
    "ddpm = DDPMScheduler(num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 batches done\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "500 batches done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-76892392a6b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Get the model prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ligdream/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffdream/scripts/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_block3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_level3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_level2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_block1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_level1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ligdream/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/diffdream/scripts/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, residual)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i, (x, targets) in enumerate(train_dataloader):\n",
    "        timesteps = torch.randint(\n",
    "            0,\n",
    "            ddpm.num_train_timesteps,\n",
    "            (x.shape[0],),\n",
    "            device=x.device,\n",
    "        ).long()\n",
    "\n",
    "        noise = torch.randn(x.shape).to(x.device)\n",
    "        noisy_x = ddpm.add_noise(x, noise, timesteps)\n",
    "\n",
    "\n",
    "        noisy_x = noisy_x.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        x = x.to(device) # Data on the GPU\n",
    "        # Get the model prediction\n",
    "\n",
    "        pred = net(noisy_x)\n",
    "\n",
    "        # Calculate the loss\n",
    "        \n",
    "        loss = loss_fn(pred, x) # How close is the output to the true 'clean' x?\n",
    "\n",
    "        losses_net.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        # Backprop and update the params:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if i%500 == 0:\n",
    "            torch.save(net.state_dict(), \"../models/state_dict_net.pt\")\n",
    "            print(\"500 batches done\")\n",
    "\n",
    "\n",
    "    # Print our the average of the loss values for this epoch:\n",
    "    avg_loss = sum(losses_net[-len(train_dataloader):])/len(train_dataloader)\n",
    "    print(f'Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}')\n",
    "\n",
    "# View the loss curve\n",
    "plt.plot(losses_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ligdream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15 | packaged by conda-forge | (default, Dec  3 2021, 18:49:41) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "143b4da7727a9152bb94050db5642443df545a5cda503424792f6e55599a2504"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
