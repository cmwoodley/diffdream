{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/miniconda3/envs/diff_dream/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from diffusers import DDPMScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,\"../scripts\")\n",
    "from get_voxels import get_mol_voxels\n",
    "from networks import Encoder, UNet3D, AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "encoder = Encoder()\n",
    "# encoder = AutoEncoder()\n",
    "encoder.to(device)\n",
    "\n",
    "# encoder.load_state_dict(torch.load(\"../models/state_dict_encoder.pt\"))\n",
    "encoder.load_state_dict(torch.load(\"../models/state_dict_autoencoder.pt\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "with open(\"../datasets/raw/zinc15_druglike_clean_canonical_max60.smi\") as f:\n",
    "    i=0\n",
    "    for i, line in enumerate(f):\n",
    "        smiles.append(line)\n",
    "        if i > 1000000:\n",
    "            break\n",
    "\n",
    "smiles = smiles[528000:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up custom dataloader with vox encoding\n",
    "\n",
    "Collate_bach generates vox representations on the fly, prevent kernel crash due to being out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, smiles):\n",
    "        self.transform = get_mol_voxels\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        return smile\n",
    "\n",
    "smile_DS = CustomImageDataset(smiles)\n",
    "\n",
    "def collate_batch(smiles):\n",
    "    inputs = []\n",
    "    target = []\n",
    "    for smile in smiles:\n",
    "        try:\n",
    "            rep, pharm = get_mol_voxels(smile)\n",
    "            inputs.append(rep)\n",
    "            target.append(pharm)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return torch.stack(inputs), torch.stack(target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader (you can mess with batch size)\n",
    "train_dataloader = DataLoader(smile_DS, batch_size=128, collate_fn=collate_batch)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epochs = 1\n",
    "\n",
    "# Our loss finction\n",
    "criterion = nn.MSELoss()\n",
    "# The optimizer\n",
    "optimizer = torch.optim.Adam(encoder.parameters())\n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses_enc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008794211\n",
      "0.00085578527\n",
      "0.0006739023\n",
      "0.00074051664\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "0.0008058819\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "0.0007644041\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "0.0007035245\n",
      "0.0007048622\n",
      "Finished epoch 0. Average enc loss for this epoch: 0.000770\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i, (x, targets) in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        encoded_tensor = encoder(x)\n",
    "        loss = criterion(encoded_tensor, targets)\n",
    "        losses_enc.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            torch.save(encoder.state_dict(), \"../models/state_dict_autoencoder.pt\")\n",
    "            print(loss.cpu().detach().numpy())\n",
    "\n",
    "    # Print our the average of the loss values for this epoch:\n",
    "    avg_loss = sum(losses_enc[-len(train_dataloader):])/len(train_dataloader)\n",
    "    print(f'Finished epoch {epoch}. Average enc loss for this epoch: {avg_loss:05f}')#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the unet\n",
    "\n",
    "Ideally would train both at the same time, but memory becomes an issue - running on a laptop with only 4GB gpu ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNet3D(in_channels=5, num_classes=5)\n",
    "net.to(device)\n",
    "\n",
    "net.load_state_dict(torch.load(\"../models/state_dict_net.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many runs through the data should we do?\n",
    "n_epochs = 1\n",
    "\n",
    "train_dataloader = DataLoader(smile_DS, batch_size=32, collate_fn=collate_batch)\n",
    "\n",
    "# Our loss finction\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(net.parameters(), lr=0.001) \n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses_net = []\n",
    "# Initialize the DDPM scheduler\n",
    "ddpm = DDPMScheduler(num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 batches done\n",
      "500 batches done\n",
      "500 batches done\n",
      "500 batches done\n",
      "Gen_rep_fails\n",
      "500 batches done\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "Gen_rep_fails\n",
      "500 batches done\n",
      "Gen_rep_fails\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for i, (x, targets) in enumerate(train_dataloader):\n",
    "        timesteps = torch.randint(\n",
    "            0,\n",
    "            ddpm.num_train_timesteps,\n",
    "            (x.shape[0],),\n",
    "            device=x.device,\n",
    "        ).long()\n",
    "\n",
    "        noise = torch.randn(x.shape).to(x.device)\n",
    "        noisy_x = ddpm.add_noise(x, noise, timesteps)\n",
    "\n",
    "\n",
    "        noisy_x = noisy_x.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        x = x.to(device) # Data on the GPU\n",
    "        # Get the model prediction\n",
    "\n",
    "        pred = net(noisy_x)\n",
    "\n",
    "        # Calculate the loss\n",
    "        \n",
    "        loss = loss_fn(pred, x) # How close is the output to the true 'clean' x?\n",
    "\n",
    "        losses_net.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        # Backprop and update the params:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if i%500 == 0:\n",
    "            torch.save(net.state_dict(), \"../models/state_dict_net.pt\")\n",
    "            print(\"500 batches done\")\n",
    "\n",
    "\n",
    "    # Print our the average of the loss values for this epoch:\n",
    "    avg_loss = sum(losses_net[-len(train_dataloader):])/len(train_dataloader)\n",
    "    print(f'Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}')\n",
    "\n",
    "# View the loss curve\n",
    "plt.plot(losses_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_dream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cb8e36acd842bb50691c6a741eb0389216366ee7631a59d2b73633ccc1d0e75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
